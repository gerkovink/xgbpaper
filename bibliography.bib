
@article{zotero-1,
}

@article{kangPreventionHandlingMissing2013,
	title = {The prevention and handling of the missing data},
	volume = {64},
	issn = {2005-6419, 2005-7563},
	url = {http://ekja.org/journal/view.php?doi=10.4097/kjae.2013.64.5.402},
	doi = {10.4097/kjae.2013.64.5.402},
	language = {en},
	number = {5},
	urldate = {2024-03-13},
	journal = {Korean Journal of Anesthesiology},
	author = {Kang, Hyun},
	year = {2013},
	pages = {402},
	file = {Full Text:/Users/Shehw001/Zotero/storage/PUNLFJDK/Kang - 2013 - The prevention and handling of the missing data.pdf:application/pdf},
}

@article{sunDeepLearningConventional2023,
	title = {Deep learning versus conventional methods for missing data imputation: {A} review and comparative study},
	volume = {227},
	issn = {09574174},
	shorttitle = {Deep learning versus conventional methods for missing data imputation},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417423007030},
	doi = {10.1016/j.eswa.2023.120201},
	language = {en},
	urldate = {2024-03-13},
	journal = {Expert Systems with Applications},
	author = {Sun, Yige and Li, Jing and Xu, Yifan and Zhang, Tingting and Wang, Xiaofeng},
	month = oct,
	year = {2023},
	pages = {120201},
}

@article{schoutenGeneratingMissingValues2018,
	title = {Generating missing values for simulation purposes: a multivariate amputation procedure},
	volume = {88},
	issn = {0094-9655, 1563-5163},
	shorttitle = {Generating missing values for simulation purposes},
	url = {https://www.tandfonline.com/doi/full/10.1080/00949655.2018.1491577},
	doi = {10.1080/00949655.2018.1491577},
	language = {en},
	number = {15},
	urldate = {2024-03-13},
	journal = {Journal of Statistical Computation and Simulation},
	author = {Schouten, Rianne Margaretha and Lugtig, Peter and Vink, Gerko},
	month = oct,
	year = {2018},
	pages = {2909--2930},
	file = {Full Text:/Users/Shehw001/Zotero/storage/2AWN8HXN/Schouten et al. - 2018 - Generating missing values for simulation purposes.pdf:application/pdf},
}

@techreport{R-base,
	address = {Vienna, Austria},
	type = {manual},
	title = {R: {A} language and environment for statistical computing},
	url = {https://www.R-project.org},
	institution = {R Foundation for Statistical Computing},
	author = {{R Core Team}},
	year = {2019},
}

@article{tidyverse,
	title = {Welcome to the {\textless}span class="nocase"{\textgreater}tidyverse{\textless}/span{\textgreater}},
	volume = {4},
	doi = {10.21105/joss.01686},
	number = {43},
	journal = {Journal of Open Source Software},
	author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy D'Agostino and Françoi, Romain and Grolemun, Garrett and Haye, Alex and Henr, Lionel and Heste, Jim and Kuh, Max and Pederse, Thomas Lin and Mille, Evan and Bach, Stephan Milton and Müll, Kirill and , Jeroen Oo and , David Robins and , Dana Paige Seid and , Vitalie Spi and , Kohske Takahas and , Davis Vaugh and , Claus Wil and , Kara W and , Hiroaki Yutani},
	year = {2019},
	pages = {1686},
}

@article{mice,
	title = {{\textless}span class="nocase"{\textgreater}mice{\textless}/span{\textgreater}: {Multivariate} imputation by chained equations in {R}},
	volume = {45},
	doi = {10.18637/jss.v045.i03},
	number = {3},
	journal = {Journal of Statistical Software},
	author = {van Buuren, Stef and Groothuis-Oudshoorn, Karin},
	year = {2011},
	pages = {1--67},
}

@techreport{ggmice,
	type = {manual},
	title = {ggmice: {Visualizations} for 'mice' with 'ggplot2'},
	url = {https://github.com/amices/ggmice},
	author = {Oberman, Hanne},
	year = {2024},
	annote = {R package version 0.1.0.9000, https://amices.org/, https://amices.org/ggmice/},
}

@techreport{kableExtra,
	type = {manual},
	title = {{kableExtra}: {Construct} complex table with 'kable' and pipe syntax},
	url = {https://CRAN.R-project.org/package=kableExtra},
	author = {Zhu, Hao},
	year = {2021},
	annote = {R package version 1.3.4},
}

@article{naniar,
	title = {Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations},
	volume = {105},
	doi = {10.18637/jss.v105.i07},
	number = {7},
	journal = {Journal of Statistical Software},
	author = {Tierney, Nicholas and Cook, Dianne},
	year = {2023},
	pages = {1--31},
}

@techreport{psych,
	address = {Evanston, Illinois},
	type = {manual},
	title = {psych: {Procedures} for psychological, psychometric, and personality research},
	url = {https://CRAN.R-project.org/package=psych},
	institution = {Northwestern University},
	author = {{William Revelle}},
	year = {2023},
	annote = {R package version 2.3.9},
}

@misc{nhanes,
	title = {National health and nutrition examination survey ({NHANES}), 2007-2008},
	author = {{United States Department of Health and Human Services. Centers for Disease Control and Prevention. National Center for Health Statistics}},
	year = {2012},
	doi = {10.3886/ICPSR25505.v3},
	note = {tex.entrytype: data},
}

@book{Hand_2022,
	title = {Dark data},
	publisher = {Princeton University Press},
	author = {Hand, David J.},
	year = {2022},
}

@article{Rubin_1994,
	title = {Missing data, imputation, and the bootstrap},
	volume = {89},
	issn = {01621459},
	url = {http://www.jstor.org/stable/2290846},
	number = {426},
	urldate = {2024-03-13},
	journal = {Journal of the American Statistical Association},
	author = {Efron, Bradley},
	year = {1994},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {463--475},
}

@incollection{Van_Buuren_2018,
	address = {New York, New York},
	edition = {Second Edition},
	series = {Interdisciplinary statistics series},
	title = {Chapter 2: {Multiple} imputation},
	url = {https://stefvanbuuren.name/fimd/sec-historic.html},
	booktitle = {Flexible imputation of missing data},
	publisher = {CRC Press},
	author = {Van Buuren, Stef},
	year = {2018},
}

@incollection{Van_Buuren_2018,
	address = {New York, New York},
	edition = {Second Edition},
	series = {Interdisciplinary statistics series},
	title = {Chapter 6.5: {Algorithmic} options},
	url = {https://stefvanbuuren.name/fimd/sec-algoptions.html},
	booktitle = {Flexible imputation of missing data},
	publisher = {CRC Press},
	author = {Van Buuren, Stef},
	year = {2018},
}

@techreport{broom,
	type = {manual},
	title = {broom.mixed: {Tidying} methods for mixed models},
	url = {https://CRAN.R-project.org/package=broom.mixed},
	author = {Bolker, Ben and Robinson, David},
	year = {2022},
	annote = {R package version 0.2.9.4},
}

@techreport{vtable,
	type = {manual},
	title = {vtable: {Variable} table for variable documentation},
	url = {https://CRAN.R-project.org/package=vtable},
	author = {Huntington-Klein, Nick},
	year = {2023},
	annote = {R package version 1.4.6},
}

@misc{Rubin_2022,
	title = {Chapter 9: {Rubin}’s rules: {Bookₘi}.knit},
	url = {https://bookdown.org/mwheymans/bookmi/rubins-rules.html},
	author = {Rubin, D. B.},
	month = sep,
	year = {2022},
}

@misc{Van_Buuren_2024,
	title = {Chapter 1.6: {Ad}-hoc solutions},
	url = {https://stefvanbuuren.name/fimd/sec-simplesolutions.html},
	author = {Van Buuren, Stef},
	month = apr,
	year = {2024},
}

@article{zotero-29,
}

@article{bartlettMultipleImputationCovariates2015,
	title = {Multiple imputation of covariates by fully conditional specification: {Accommodating} the substantive model},
	volume = {24},
	issn = {0962-2802},
	shorttitle = {Multiple imputation of covariates by fully conditional specification},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4513015/},
	doi = {10.1177/0962280214521348},
	abstract = {Missing covariate data commonly occur in epidemiological and clinical research, and are often dealt with using multiple imputation. Imputation of partially observed covariates is complicated if the substantive model is non-linear (e.g. Cox proportional hazards model), or contains non-linear (e.g. squared) or interaction terms, and standard software implementations of multiple imputation may impute covariates from models that are incompatible with such substantive models. We show how imputation by fully conditional specification, a popular approach for performing multiple imputation, can be modified so that covariates are imputed from models which are compatible with the substantive model. We investigate through simulation the performance of this proposal, and compare it with existing approaches. Simulation results suggest our proposal gives consistent estimates for a range of common substantive models, including models which contain non-linear covariate effects or interactions, provided data are missing at random and the assumed imputation models are correctly specified and mutually compatible. Stata software implementing the approach is freely available.},
	number = {4},
	urldate = {2024-04-02},
	journal = {Statistical Methods in Medical Research},
	author = {Bartlett, Jonathan W and Seaman, Shaun R and White, Ian R and Carpenter, James R},
	month = aug,
	year = {2015},
	pmid = {24525487},
	pmcid = {PMC4513015},
	pages = {462--487},
	annote = {Intro para1
},
	file = {Full Text PDF:/Users/Shehw001/Zotero/storage/UG8QXG3W/Bartlett et al. - 2015 - Multiple imputation of covariates by fully conditi.pdf:application/pdf},
}

@article{shahComparisonRandomForest2014,
	title = {Comparison of {Random} {Forest} and {Parametric} {Imputation} {Models} for {Imputing} {Missing} {Data} {Using} {MICE}: {A} {CALIBER} {Study}},
	volume = {179},
	issn = {0002-9262},
	shorttitle = {Comparison of {Random} {Forest} and {Parametric} {Imputation} {Models} for {Imputing} {Missing} {Data} {Using} {MICE}},
	url = {https://doi.org/10.1093/aje/kwt312},
	doi = {10.1093/aje/kwt312},
	abstract = {Multivariate imputation by chained equations (MICE) is commonly used for imputing missing data in epidemiologic research. The “true” imputation model may contain nonlinearities which are not included in default imputation models. Random forest imputation is a machine learning technique which can accommodate nonlinearities and interactions and does not require a particular regression model to be specified. We compared parametric MICE with a random forest-based MICE algorithm in 2 simulation studies. The first study used 1,000 random samples of 2,000 persons drawn from the 10,128 stable angina patients in the CALIBER database (Cardiovascular Disease Research using Linked Bespoke Studies and Electronic Records; 2001–2010) with complete data on all covariates. Variables were artificially made “missing at random,” and the bias and efficiency of parameter estimates obtained using different imputation methods were compared. Both MICE methods produced unbiased estimates of (log) hazard ratios, but random forest was more efficient and produced narrower confidence intervals. The second study used simulated data in which the partially observed variable depended on the fully observed variables in a nonlinear way. Parameter estimates were less biased using random forest MICE, and confidence interval coverage was better. This suggests that random forest imputation may be useful for imputing complex epidemiologic data sets in which some patients have missing data.},
	number = {6},
	urldate = {2024-04-02},
	journal = {American Journal of Epidemiology},
	author = {Shah, Anoop D. and Bartlett, Jonathan W. and Carpenter, James and Nicholas, Owen and Hemingway, Harry},
	month = mar,
	year = {2014},
	pages = {764--774},
	file = {Full Text PDF:/Users/Shehw001/Zotero/storage/IR7SQ34C/Shah et al. - 2014 - Comparison of Random Forest and Parametric Imputat.pdf:application/pdf},
}

@article{wulffMultipleImputationChained2017,
	title = {Multiple {Imputation} by {Chained} {Equations} in {Praxis}: {Guidelines} and {Review}},
	volume = {15},
	abstract = {Multiple imputation by chained equations (MICE) is an effective tool to handle missing data - an almost unavoidable problem in quantitative data analysis. However, despite the empirical and theoretical evidence supporting the use of MICE, researchers in the social sciences often resort to inferior approaches unnecessarily risking erroneous results. The complexity of the decision process when encountering missing data may be what is discouraging potential users from adopting the appropriate technique. In this article, we develop straightforward step-by-step graphical guidelines on how to handle missing data based on a comprehensive literature review. It is our hope that these guidelines can help improve current standards of handling missing data. The guidelines incorporate recent innovations on how to handle missing data such as random forests and predictive mean matching. Thus, the data analysts who already actively apply MICE may use it to review some of the newest developments. We demonstrate how the guidelines can be used in praxis using the statistical program R and data from the European Social Survey. We demonstrate central decisions such as variable selection and number of imputations as well as how to handle typical challenges such as skewed distributions and data transformations. These guidelines will enable a social science researcher to go through the process of handling missing data while adhering to the newest developments in the field.},
	language = {en},
	number = {1},
	author = {Wulff, Jesper N and Ejlskov, Linda},
	year = {2017},
	file = {Wulff and Ejlskov - 2017 - Multiple Imputation by Chained Equations in Praxis.pdf:/Users/Shehw001/Zotero/storage/9ES4ARZH/Wulff and Ejlskov - 2017 - Multiple Imputation by Chained Equations in Praxis.pdf:application/pdf},
}

@article{hongAccuracyRandomforestbasedImputation2020,
	title = {Accuracy of random-forest-based imputation of missing data in the presence of non-normality, non-linearity, and interaction},
	volume = {20},
	issn = {1471-2288},
	url = {https://doi.org/10.1186/s12874-020-01080-1},
	doi = {10.1186/s12874-020-01080-1},
	abstract = {Missing data are common in statistical analyses, and imputation methods based on random forests (RF) are becoming popular for handling missing data especially in biomedical research. Unlike standard imputation approaches, RF-based imputation methods do not assume normality or require specification of parametric models. However, it is still inconclusive how they perform for non-normally distributed data or when there are non-linear relationships or interactions.},
	language = {en},
	number = {1},
	urldate = {2024-04-03},
	journal = {BMC Medical Research Methodology},
	author = {Hong, Shangzhi and Lynn, Henry S.},
	month = jul,
	year = {2020},
	keywords = {Imputation accuracy, Missing data imputation, Random forest},
	pages = {199},
	file = {Full Text PDF:/Users/Shehw001/Zotero/storage/JZ2C6H3C/Hong and Lynn - 2020 - Accuracy of random-forest-based imputation of miss.pdf:application/pdf},
}

@misc{MultipleImputationXGBoost,
	title = {Multiple {Imputation} {Through} {XGBoost}},
	url = {https://www.tandfonline.com/doi/epdf/10.1080/10618600.2023.2252501?needAccess=true},
	language = {en},
	urldate = {2024-04-03},
	note = {ISSN: 1061-8600},
	file = {Snapshot:/Users/Shehw001/Zotero/storage/UXS5FJEU/10618600.2023.html:text/html},
}

@article{chhabraComparisonMultipleImputation2017,
	title = {A {Comparison} of {Multiple} {Imputation} {Methods} for {Data} with {Missing} {Values}},
	copyright = {Copyright (c)},
	issn = {0974-5645},
	url = {https://ischolar.sscldl.in/index.php/indjst/article/view/150598},
	doi = {10.17485/ijst/2017/v10i19/150598},
	abstract = {Missing data is relatively common in all type of research, which can reduce the statistical power and have biased results if not handled properly. Multivariate Imputation by Chained Equations (MICE) has emerged as one of the principled method of addressing missing data. This paper provides comparison of MICE using various methods to deal with missing values. The chained equations approach is very flexible and can handle various types of data such as continuous or binary as well as various missing data patterns. Objectives: To discuss commonly used techniques for handling missing data and common issues that could arise when these techniques are used. In particular, we will focus on different approaches of one of the most popular methods, Multiple Imputation using Chained Equations (MICE). Methods/Statistical Analysis: Multivariate Imputation by Chained Equation is a statistical method for addressing missing value imputation. The paper will focus on Multiple Imputation using Predictive Mean Matching, Multiple Random Forest Regression Imputation, Multiple Bayesian Regression Imputation, Multiple Linear Regression using Non-Bayesian Imputation, Multiple Classification and Regression Tree (CART), Multiple Linear Regression with Bootstrap Imputation which provides a general framework for analyzing data with missing values. Findings: We have chosen to explore Multiple Imputation using MICE through an examination of sample data set. Our analysis confirms that the power of Multiple Imputations lies in getting smaller standard errors and narrower confidence intervals. The smaller is the standard error and narrower is the confidence interval; the predicted value is more accurate, thus, minimizing the bias and inefficiency considerably. In our results from sample data set, it has been observed that standard error and mean confidence interval length is the least in case of Multiple Imputation combined with Bayesian Regression. Also, it is obvious from the density plot that the imputed values are more close to the observed values in this method than other methods. Even in case of random forest, the results are quite close to Bayesian Regression. Application/Improvements: These Multiple Imputation methods can further be combined with machine learning and Genetic Algorithms on real set data to further reduce the bias and inefficiency.},
	language = {en},
	urldate = {2024-04-03},
	journal = {Indian Journal of Science and Technology},
	author = {Chhabra, Geeta and Vashisht, Vasudha and Ranjan, Jayanthi},
	month = may,
	year = {2017},
	keywords = {Missing at Random (MAR), Missing Completely at Random, Multiple Imputation, Not Missing at Random (NMAR).},
	file = {Full Text PDF:/Users/Shehw001/Zotero/storage/7EHHXA8C/Chhabra et al. - 2017 - A Comparison of Multiple Imputation Methods for Da.pdf:application/pdf},
}

@misc{GeneratingMissingValues,
	title = {Generating missing values for simulation purposes: a multivariate amputation procedure},
	shorttitle = {Generating missing values for simulation purposes},
	url = {https://www.tandfonline.com/doi/epdf/10.1080/00949655.2018.1491577?needAccess=true},
	language = {en},
	urldate = {2024-04-03},
	note = {ISSN: 0094-9655},
	file = {Snapshot:/Users/Shehw001/Zotero/storage/Q8Y68D8T/00949655.2018.html:text/html},
}

@article{vinkMultipleImputationSquared2013,
	title = {Multiple {Imputation} of {Squared} {Terms}},
	volume = {42},
	issn = {0049-1241},
	url = {https://doi.org/10.1177/0049124113502943},
	doi = {10.1177/0049124113502943},
	abstract = {We propose a new multiple imputation technique for imputing squares. Current methods yield either unbiased regression estimates or preserve data relations. No method, however, seems to deliver both, which limits researchers in the implementation of regression analysis in the presence of missing data. Besides, current methods only work under a missing completely at random (MCAR) mechanism. Our method for imputing squares uses a polynomial combination. The proposed method yields both unbiased regression estimates, while preserving the quadratic relations in the data for both missing at random and MCAR mechanisms.},
	language = {en},
	number = {4},
	urldate = {2024-04-03},
	journal = {Sociological Methods \& Research},
	author = {Vink, Gerko and van Buuren, Stef},
	month = nov,
	year = {2013},
	note = {Publisher: SAGE Publications Inc},
	pages = {598--607},
}

@article{vinkMultipleImputationSquared2013a,
	title = {Multiple {Imputation} of {Squared} {Terms}},
	volume = {42},
	issn = {0049-1241, 1552-8294},
	url = {http://journals.sagepub.com/doi/10.1177/0049124113502943},
	doi = {10.1177/0049124113502943},
	abstract = {We propose a new multiple imputation technique for imputing squares. Current methods yield either unbiased regression estimates or preserve data relations. No method, however, seems to deliver both, which limits researchers in the implementation of regression analysis in the presence of missing data. Besides, current methods only work under a missing completely at random (MCAR) mechanism. Our method for imputing squares uses a polynomial combination. The proposed method yields both unbiased regression estimates, while preserving the quadratic relations in the data for both missing at random and MCAR mechanisms.},
	language = {en},
	number = {4},
	urldate = {2024-04-03},
	journal = {Sociological Methods \& Research},
	author = {Vink, Gerko and Van Buuren, Stef},
	month = nov,
	year = {2013},
	pages = {598--607},
}

@article{leeMultipleImputationMissing2010,
	title = {Multiple {Imputation} for {Missing} {Data}: {Fully} {Conditional} {Specification} {Versus} {Multivariate} {Normal} {Imputation}},
	volume = {171},
	issn = {0002-9262, 1476-6256},
	shorttitle = {Multiple {Imputation} for {Missing} {Data}},
	url = {https://academic.oup.com/aje/article-lookup/doi/10.1093/aje/kwp425},
	doi = {10.1093/aje/kwp425},
	language = {en},
	number = {5},
	urldate = {2024-04-03},
	journal = {American Journal of Epidemiology},
	author = {Lee, K. J. and Carlin, J. B.},
	month = mar,
	year = {2010},
	pages = {624--632},
	file = {Lee and Carlin - 2010 - Multiple Imputation for Missing Data Fully Condit.pdf:/Users/Shehw001/Zotero/storage/XWX8FB4F/Lee and Carlin - 2010 - Multiple Imputation for Missing Data Fully Condit.pdf:application/pdf},
}

@article{wijesuriyaEvaluationApproachesAccommodating2022,
	title = {Evaluation of approaches for accommodating interactions and non-linear terms in multiple imputation of incomplete three-level data},
	volume = {64},
	issn = {1521-4036},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.202000343},
	doi = {10.1002/bimj.202000343},
	abstract = {Three-level data structures arising from repeated measures on individuals clustered within larger units are common in health research studies. Missing data are prominent in such studies and are often handled via multiple imputation (MI). Although several MI approaches can be used to account for the three-level structure, including adaptations to single- and two-level approaches, when the substantive analysis model includes interactions or quadratic effects, these too need to be accommodated in the imputation model. In such analyses, substantive model compatible (SMC) MI has shown great promise in the context of single-level data. Although there have been recent developments in multilevel SMC MI, to date only one approach that explicitly handles incomplete three-level data is available. Alternatively, researchers can use pragmatic adaptations to single- and two-level MI approaches, or two-level SMC-MI approaches. We describe the available approaches and evaluate them via simulations in the context of three three-level random effects analysis models involving an interaction between the incomplete time-varying exposure and time, an interaction between the time-varying exposure and an incomplete time-fixed confounder, or a quadratic effect of the exposure. Results showed that all approaches considered performed well in terms of bias and precision when the target analysis involved an interaction with time, but the three-level SMC MI approach performed best when the target analysis involved an interaction between the time-varying exposure and an incomplete time-fixed confounder, or a quadratic effect of the exposure. We illustrate the methods using data from the Childhood to Adolescence Transition Study.},
	language = {en},
	number = {8},
	urldate = {2024-04-03},
	journal = {Biometrical Journal},
	author = {Wijesuriya, Rushani and Moreno-Betancur, Margarita and Carlin, John B. and De Silva, Anurika P. and Lee, Katherine J.},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bimj.202000343},
	keywords = {congeniality, interactions, multiple imputation, non-linearities, substantive model compatible, three-level data},
	pages = {1404--1425},
	file = {Full Text PDF:/Users/Shehw001/Zotero/storage/Y4JMCVWS/Wijesuriya et al. - 2022 - Evaluation of approaches for accommodating interac.pdf:application/pdf;Snapshot:/Users/Shehw001/Zotero/storage/3CKEAFVM/bimj.html:text/html},
}

@article{linMissingValueImputation2020,
	title = {Missing value imputation: a review and analysis of the literature (2006–2017)},
	volume = {53},
	issn = {1573-7462},
	shorttitle = {Missing value imputation},
	url = {https://doi.org/10.1007/s10462-019-09709-4},
	doi = {10.1007/s10462-019-09709-4},
	abstract = {Missing value imputation (MVI) has been studied for several decades being the basic solution method for incomplete dataset problems, specifically those where some data samples contain one or more missing attribute values. This paper aims at reviewing and analyzing related studies carried out in recent decades, from the experimental design perspective. Altogether, 111 journal papers published from 2006 to 2017 are reviewed and analyzed. In addition, several technical issues encountered during the MVI process are addressed, such as the choice of datasets, missing rates and missingness mechanisms, and the MVI techniques and evaluation metrics employed, are discussed. The results of analysis of these issues allow limitations in the existing body of literature to be identified based upon which some directions for future research can be gleaned.},
	language = {en},
	number = {2},
	urldate = {2024-04-03},
	journal = {Artificial Intelligence Review},
	author = {Lin, Wei-Chao and Tsai, Chih-Fong},
	month = feb,
	year = {2020},
	keywords = {Data mining, Imputation, Incomplete dataset, Missing values, Supervised learning},
	pages = {1487--1509},
	file = {Full Text PDF:/Users/Shehw001/Zotero/storage/DB3SYP4Y/Lin and Tsai - 2020 - Missing value imputation a review and analysis of.pdf:application/pdf},
}

@article{stekhovenMissForestNonparametricMissing2012,
	title = {{MissForest}—non-parametric missing value imputation for mixed-type data},
	volume = {28},
	issn = {1367-4811, 1367-4803},
	url = {https://academic.oup.com/bioinformatics/article/28/1/112/219101},
	doi = {10.1093/bioinformatics/btr597},
	abstract = {Abstract
            Motivation: Modern data acquisition based on high-throughput technology is often facing the problem of missing data. Algorithms commonly used in the analysis of such large-scale data often depend on a complete set. Missing value imputation offers a solution to this problem. However, the majority of available imputation methods are restricted to one type of variable only: continuous or categorical. For mixed-type data, the different types are usually handled separately. Therefore, these methods ignore possible relations between variable types. We propose a non-parametric method which can cope with different types of variables simultaneously.
            Results: We compare several state of the art methods for the imputation of missing values. We propose and evaluate an iterative imputation method (missForest) based on a random forest. By averaging over many unpruned classification or regression trees, random forest intrinsically constitutes a multiple imputation scheme. Using the built-in out-of-bag error estimates of random forest, we are able to estimate the imputation error without the need of a test set. Evaluation is performed on multiple datasets coming from a diverse selection of biological fields with artificially introduced missing values ranging from 10\% to 30\%. We show that missForest can successfully handle missing values, particularly in datasets including different types of variables. In our comparative study, missForest outperforms other methods of imputation especially in data settings where complex interactions and non-linear relations are suspected. The out-of-bag imputation error estimates of missForest prove to be adequate in all settings. Additionally, missForest exhibits attractive computational efficiency and can cope with high-dimensional data.
            Availability: The ℝ package missForest is freely available from http://stat.ethz.ch/CRAN/.
            Contact:  stekhoven@stat.math.ethz.ch; buhlmann@stat.math.ethz.ch},
	language = {en},
	number = {1},
	urldate = {2024-04-03},
	journal = {Bioinformatics},
	author = {Stekhoven, Daniel J. and Bühlmann, Peter},
	month = jan,
	year = {2012},
	pages = {112--118},
	annote = {[TLDR] In this comparative study, missForest outperforms other methods of imputation especially in data settings where complex interactions and non-linear relations are suspected and the out-of-bag imputation error estimates of missForest prove to be adequate in all settings.},
	file = {Full Text:/Users/Shehw001/Zotero/storage/K92HNG3N/Stekhoven and Bühlmann - 2012 - MissForest—non-parametric missing value imputation.pdf:application/pdf},
}

@article{seamanMultipleImputationMissing2012,
	title = {Multiple imputation of missing covariates with non-linear effects and interactions: an evaluation of statistical methods},
	volume = {12},
	issn = {1471-2288},
	shorttitle = {Multiple imputation of missing covariates with non-linear effects and interactions},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3403931/},
	doi = {10.1186/1471-2288-12-46},
	abstract = {Background
Multiple imputation is often used for missing data. When a model contains as covariates more than one function of a variable, it is not obvious how best to impute missing values in these covariates. Consider a regression with outcome Y and covariates X and X2. In 'passive imputation' a value X* is imputed for X and then X2 is imputed as (X*)2. A recent proposal is to treat X2 as 'just another variable' (JAV) and impute X and X2 under multivariate normality.

Methods
We use simulation to investigate the performance of three methods that can easily be implemented in standard software: 1) linear regression of X on Y to impute X then passive imputation of X2; 2) the same regression but with predictive mean matching (PMM); and 3) JAV. We also investigate the performance of analogous methods when the analysis involves an interaction, and study the theoretical properties of JAV. The application of the methods when complete or incomplete confounders are also present is illustrated using data from the EPIC Study.

Results
JAV gives consistent estimation when the analysis is linear regression with a quadratic or interaction term and X is missing completely at random. When X is missing at random, JAV may be biased, but this bias is generally less than for passive imputation and PMM. Coverage for JAV was usually good when bias was small. However, in some scenarios with a more pronounced quadratic effect, bias was large and coverage poor. When the analysis was logistic regression, JAV's performance was sometimes very poor. PMM generally improved on passive imputation, in terms of bias and coverage, but did not eliminate the bias.

Conclusions
Given the current state of available software, JAV is the best of a set of imperfect imputation methods for linear regression with a quadratic or interaction effect, but should not be used for logistic regression.},
	urldate = {2024-04-03},
	journal = {BMC Medical Research Methodology},
	author = {Seaman, Shaun R and Bartlett, Jonathan W and White, Ian R},
	month = apr,
	year = {2012},
	pmid = {22489953},
	pmcid = {PMC3403931},
	pages = {46},
	file = {Full Text PDF:/Users/Shehw001/Zotero/storage/R8AYZMA5/Seaman et al. - 2012 - Multiple imputation of missing covariates with non.pdf:application/pdf},
}

@article{littleMissingDataAdjustmentsLarge1988,
	title = {Missing-{Data} {Adjustments} in {Large} {Surveys}},
	volume = {6},
	issn = {0735-0015},
	url = {https://www.jstor.org/stable/1391878},
	doi = {10.2307/1391878},
	abstract = {Useful properties of a general-purpose imputation method for numerical data are suggested and discussed in the context of several large government surveys. Imputation based on predictive mean matching is proposed as a useful extension of methods in existing practice, and versions of the method are presented for unit nonresponse and item nonresponse with a general pattern of missingness. Extensions of the method to provide multiple imputations are also considered. Pros and cons of weighting adjustments are discussed, and weighting-based analogs to predictive mean matching are outlined.},
	number = {3},
	urldate = {2024-04-08},
	journal = {Journal of Business \& Economic Statistics},
	author = {Little, Roderick J. A.},
	year = {1988},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {287--296},
}

@article{rubinInferenceMissingData1976,
	title = {Inference and missing data},
	volume = {63},
	issn = {0006-3444},
	url = {https://doi.org/10.1093/biomet/63.3.581},
	doi = {10.1093/biomet/63.3.581},
	abstract = {When making sampling distribution inferences about the parameter of the data, θ, it is appropriate to ignore the process that causes missing data if the missing data are ‘missing at random’ and the observed data are ‘observed at random’, but these inferences are generally conditional on the observed pattern of missing data. When making direct-likelihood or Bayesian inferences about θ, it is appropriate to ignore the process that causes missing data if the missing data are missing at random and the parameter of the missing data process is ‘distinct’ from θ. These conditions are the weakest general conditions under which ignoring the process that causes missing data always leads to correct inferences.},
	number = {3},
	urldate = {2024-04-08},
	journal = {Biometrika},
	author = {RUBIN, DONALD B.},
	month = dec,
	year = {1976},
	pages = {581--592},
	file = {Snapshot:/Users/Shehw001/Zotero/storage/UV8UZ675/270932.html:text/html},
}

@article{nijmanRealtimeImputationMissing2021,
	title = {Real-time imputation of missing predictor values in clinical practice},
	volume = {2},
	issn = {2634-3916},
	url = {https://doi.org/10.1093/ehjdh/ztaa016},
	doi = {10.1093/ehjdh/ztaa016},
	abstract = {Use of prediction models is widely recommended by clinical guidelines, but usually requires complete information on all predictors, which is not always available in daily practice. We aim to describe two methods for real-time handling of missing predictor values when using prediction models in practice.We compare the widely used method of mean imputation (M-imp) to a method that personalizes the imputations by taking advantage of the observed patient characteristics. These characteristics may include both prediction model variables and other characteristics (auxiliary variables). The method was implemented using imputation from a joint multivariate normal model of the patient characteristics (joint modelling imputation; JMI). Data from two different cardiovascular cohorts with cardiovascular predictors and outcome were used to evaluate the real-time imputation methods. We quantified the prediction model’s overall performance [mean squared error (MSE) of linear predictor], discrimination (c-index), calibration (intercept and slope), and net benefit (decision curve analysis). When compared with mean imputation, JMI substantially improved the MSE (0.10 vs. 0.13), c-index (0.70 vs. 0.68), and calibration (calibration-in-the-large: 0.04 vs. 0.06; calibration slope: 1.01 vs. 0.92), especially when incorporating auxiliary variables. When the imputation method was based on an external cohort, calibration deteriorated, but discrimination remained similar.We recommend JMI with auxiliary variables for real-time imputation of missing values, and to update imputation models when implementing them in new settings or (sub)populations.},
	number = {1},
	urldate = {2024-04-08},
	journal = {European Heart Journal - Digital Health},
	author = {Nijman, Steven W J and Hoogland, Jeroen and Groenhof, T Katrien J and Brandjes, Menno and Jacobs, John J L and Bots, Michiel L and Asselbergs, Folkert W and Moons, Karel G M and Debray, Thomas P A and {On behalf of the UCC-CVRM and UCC-SMART study groups}},
	month = mar,
	year = {2021},
	pages = {154--164},
	file = {Full Text PDF:/Users/Shehw001/Zotero/storage/XEEFJZ7K/Nijman et al. - 2021 - Real-time imputation of missing predictor values i.pdf:application/pdf;Snapshot:/Users/Shehw001/Zotero/storage/MNKA4C7W/6042147.html:text/html},
}

@incollection{Rubin1987,
	title = {Rubin, page 76},
	isbn = {978-0-470-31669-6},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470316696.ch3},
	abstract = {The prelims comprise: Introduction and Summary of Repeated-Imputation Inferences Key Results for Analysis When the Multiple Imputations Are Repeated Draws from the Posterior Distribution of the Missing Values Inference for Scalar Estimands from a Modest Number of Repeated Completed-Data Means and Variances Significance Levels for Multicomponent Estimands from a Modest Number of Repeated Completed-Data Means and Variance-Covariance Matrices Significance Levels from Repeated Completed-Data Significance Levels Relating the Completed-Data and Complete-Data Posterior Distributions When the Sampling Mechanism is Ignorable},
	language = {en},
	urldate = {2024-04-08},
	booktitle = {Multiple {Imputation} for {Nonresponse} in {Surveys}},
	publisher = {John Wiley \& Sons, Ltd},
	year = {1987},
	doi = {10.1002/9780470316696.ch3},
	note = {Section: 3
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470316696.ch3},
	keywords = {multiple imputation, normal model, posterior distribution, posterior mean and variance, regression coefficients},
	pages = {75--112},
	file = {Snapshot:/Users/Shehw001/Zotero/storage/M6IJ66RU/9780470316696.html:text/html},
}

@article{obermanStandardizedEvaluationImputation2024,
	title = {Toward a standardized evaluation of imputation methodology},
	volume = {66},
	copyright = {© 2023 The Authors. Biometrical Journal published by Wiley-VCH GmbH.},
	issn = {1521-4036},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.202200107},
	doi = {10.1002/bimj.202200107},
	abstract = {Developing new imputation methodology has become a very active field. Unfortunately, there is no consensus on how to perform simulation studies to evaluate the properties of imputation methods. In part, this may be due to different aims between fields and studies. For example, when evaluating imputation techniques aimed at prediction, different aims may be formulated than when statistical inference is of interest. The lack of consensus may also stem from different personal preferences or scientific backgrounds. All in all, the lack of common ground in evaluating imputation methodology may lead to suboptimal use in practice. In this paper, we propose a move toward a standardized evaluation of imputation methodology. To demonstrate the need for standardization, we highlight a set of possible pitfalls that bring forth a chain of potential problems in the objective assessment of the performance of imputation routines. Additionally, we suggest a course of action for simulating and evaluating missing data problems. Our suggested course of action is by no means meant to serve as a complete cookbook, but rather meant to incite critical thinking and a move to objective and fair evaluations of imputation methodology. We invite the readers of this paper to contribute to the suggested course of action.},
	language = {en},
	number = {1},
	urldate = {2024-04-08},
	journal = {Biometrical Journal},
	author = {Oberman, Hanne I. and Vink, Gerko},
	year = {2024},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bimj.202200107},
	keywords = {evaluation, imputation, missing data, simulation studies},
	pages = {2200107},
	file = {Full Text PDF:/Users/Shehw001/Zotero/storage/KHDKH8YT/Oberman and Vink - 2024 - Toward a standardized evaluation of imputation met.pdf:application/pdf;Snapshot:/Users/Shehw001/Zotero/storage/HJGJ8Y8M/bimj.html:text/html},
}

@article{vanbuurenFullyConditionalSpecification2006,
	title = {Fully conditional specification in multivariate imputation},
	volume = {76},
	issn = {0094-9655},
	url = {https://doi.org/10.1080/10629360600810434},
	doi = {10.1080/10629360600810434},
	abstract = {The use of the Gibbs sampler with fully conditionally specified models, where the distribution of each variable given the other variables is the starting point, has become a popular method to create imputations in incomplete multivariate data. The theoretical weakness of this approach is that the specified conditional densities can be incompatible, and therefore the stationary distribution to which the Gibbs sampler attempts to converge may not exist. This study investigates practical consequences of this problem by means of simulation. Missing data are created under four different missing data mechanisms. Attention is given to the statistical behavior under compatible and incompatible models. The results indicate that multiple imputation produces essentially unbiased estimates with appropriate coverage in the simple cases investigated, even for the incompatible models. Of particular interest is that these results were produced using only five Gibbs iterations starting from a simple draw from observed marginal distributions. It thus appears that, despite the theoretical weaknesses, the actual performance of conditional model specification for multivariate imputation can be quite good, and therefore deserves further study.},
	number = {12},
	urldate = {2024-04-08},
	journal = {Journal of Statistical Computation and Simulation},
	author = {Van Buuren, S. and Brand, J. P.L. and Groothuis-Oudshoorn, C. G.M. and Rubin, D. B.},
	month = dec,
	year = {2006},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10629360600810434},
	keywords = {Distributional compatibility, Gibbs sampling, Multiple imputation, Multivariate missing data, Proper imputation, Simulation},
	pages = {1049--1064},
	file = {Full Text:/Users/Shehw001/Zotero/storage/TE7GJ797/Van Buuren et al. - 2006 - Fully conditional specification in multivariate im.pdf:application/pdf},
}

@article{schaferMissingDataOur2002,
	title = {Missing data: {Our} view of the state of the art},
	volume = {7},
	issn = {1939-1463},
	shorttitle = {Missing data},
	doi = {10.1037/1082-989X.7.2.147},
	abstract = {Statistical procedures for missing data have vastly improved, yet misconception and unsound practice still abound. The authors frame the missing-data problem, review methods, offer advice, and raise issues that remain unresolved. They clear up common misunderstandings regarding the missing at random (MAR) concept. They summarize the evidence against older procedures and, with few exceptions, discourage their use. They present, in both technical and practical language, 2 general approaches that come highly recommended: maximum likelihood (ML) and Bayesian multiple imputation (MI). Newer developments are discussed, including some for dealing with missing data that are not MAR. Although not yet in the mainstream, these procedures may eventually extend the ML and MI methods that currently represent the state of the art. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {2},
	journal = {Psychological Methods},
	author = {Schafer, Joseph L. and Graham, John W.},
	year = {2002},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Maximum Likelihood, Methodology, Statistical Data, Statistical Estimation},
	pages = {147--177},
	file = {Snapshot:/Users/Shehw001/Zotero/storage/I26J8Q3I/doiLanding.html:text/html},
}

@misc{MultipleImputationDiagnostics,
	title = {Multiple {Imputation} with {Diagnostics} (mi) in {R}: {Opening} {Windows} into the {Black} {Box}-{Web} of {Science} {Core} {Collection}},
	url = {https://www.webofscience.com/wos/woscc/full-record/WOS:000298032300001?SID=EUW1ED0A21HYX2QklySh9EuNdEI1I},
	urldate = {2024-04-08},
	file = {Multiple Imputation with Diagnostics (mi) in R\: Opening Windows into the Black Box-Web of Science Core Collection:/Users/Shehw001/Zotero/storage/7B48AGV9/WOS000298032300001.html:text/html},
}

@article{dengMultipleImputationXGBoost2023,
	title = {Multiple {Imputation} {Through} {XGBoost}},
	volume = {0},
	issn = {1061-8600},
	url = {https://doi.org/10.1080/10618600.2023.2252501},
	doi = {10.1080/10618600.2023.2252501},
	abstract = {The use of multiple imputation (MI) is becoming increasingly popular for addressing missing data. Although some conventional MI approaches have been well studied and have shown empirical validity, they have limitations when processing large datasets with complex data structures. Their imputation performances usually rely on the proper specification of imputation models, and this requires expert knowledge of the inherent relations among variables. Moreover, these standard approaches tend to be computationally inefficient for medium and large datasets. In this article, we propose a scalable MI framework mixgb, which is based on XGBoost, subsampling, and predictive mean matching. Our approach leverages the power of XGBoost, a fast implementation of gradient boosted trees, to automatically capture interactions and nonlinear relations while achieving high computational efficiency. In addition, we incorporate subsampling and predictive mean matching to reduce bias and to better account for appropriate imputation variability. The proposed framework is implemented in an R package mixgb. Supplementary materials for this article are available online.},
	number = {0},
	urldate = {2024-04-08},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Deng, Yongshi and Lumley, Thomas},
	year = {2023},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10618600.2023.2252501},
	keywords = {Computational efficiency, Gradient boosted trees, Imputation variability, Large datasets, Predictive mean matching, Subsampling},
	pages = {1--19},
	file = {Full Text PDF:/Users/Shehw001/Zotero/storage/4Y8SZFDF/Deng and Lumley - 2023 - Multiple Imputation Through XGBoost.pdf:application/pdf},
}

@article{wuHyperparameterOptimizationMachine2019,
	title = {Hyperparameter {Optimization} for {Machine} {Learning} {Models} {Based} on {Bayesian} {Optimizationb}},
	volume = {17},
	issn = {1674-862X},
	url = {https://www.sciencedirect.com/science/article/pii/S1674862X19300047},
	doi = {10.11989/JEST.1674-862X.80904120},
	abstract = {Hyperparameters are important for machine learning algorithms since they directly control the behaviors of training algorithms and have a significant effect on the performance of machine learning models. Several techniques have been developed and successfully applied for certain application domains. However, this work demands professional knowledge and expert experience. And sometimes it has to resort to the brute-force search. Therefore, if an efficient hyperparameter optimization algorithm can be developed to optimize any given machine learning method, it will greatly improve the efficiency of machine learning. In this paper, we consider building the relationship between the performance of the machine learning models and their hyperparameters by Gaussian processes. In this way, the hyperparameter tuning problem can be abstracted as an optimization problem and Bayesian optimization is used to solve the problem. Bayesian optimization is based on the Bayesian theorem. It sets a prior over the optimization function and gathers the information from the previous sample to update the posterior of the optimization function. A utility function selects the next sample point to maximize the optimization function. Several experiments were conducted on standard test datasets. Experiment results show that the proposed method can find the best hyperparameters for the widely used machine learning models, such as the random forest algorithm and the neural networks, even multi-grained cascade forest under the consideration of time cost.},
	number = {1},
	urldate = {2024-04-08},
	journal = {Journal of Electronic Science and Technology},
	author = {Wu, Jia and Chen, Xiu-Yun and Zhang, Hao and Xiong, Li-Dong and Lei, Hang and Deng, Si-Hao},
	month = mar,
	year = {2019},
	keywords = {Bayesian optimization, Gaussian process, hyperparameter optimization, machine learning},
	pages = {26--40},
	file = {ScienceDirect Snapshot:/Users/Shehw001/Zotero/storage/PIFT74CZ/S1674862X19300047.html:text/html},
}

@book{HttpsStefvanbuurenName,
	title = {https://stefvanbuuren.name/fimd/sec-true.html},
	shorttitle = {https},
	url = {https://stefvanbuuren.name/fimd/sec-true.html},
	abstract = {Flexible Imputation of Missing Data, Second Edition},
	urldate = {2024-04-17},
	file = {Snapshot:/Users/Shehw001/Zotero/storage/RPKYN7UM/sec-true.html:text/html},
}

@book{rubinMultipleImputationNonresponse2004,
	address = {Hoboken, N.J},
	series = {Wiley classics library},
	title = {Multiple imputation for nonresponse in surveys},
	isbn = {978-0-471-65574-9},
	language = {eng},
	publisher = {Wiley-Interscience},
	author = {Rubin, Donald B.},
	year = {2004},
	keywords = {Multiple imputation (Statistics)},
	file = {Rubin - 2004 - Multiple imputation for nonresponse in surveys.pdf:/Users/Shehw001/Zotero/storage/3F97L33P/Rubin - 2004 - Multiple imputation for nonresponse in surveys.pdf:application/pdf},
}

@book{HttpsStefvanbuurenNamea,
	title = {https://stefvanbuuren.name/fimd/how-to-generate-multiple-imputations.html},
	shorttitle = {https},
	url = {https://stefvanbuuren.name/fimd/how-to-generate-multiple-imputations.html},
	abstract = {Flexible Imputation of Missing Data, Second Edition},
	urldate = {2024-04-17},
	file = {Snapshot:/Users/Shehw001/Zotero/storage/VFA3QUVQ/how-to-generate-multiple-imputations.html:text/html},
}

@book{buurenFlexibleImputationMissing,
	title = {Flexible {Imputation} of {Missing} {Data}},
	language = {en},
	author = {Buuren, Stef van},
	file = {Buuren - Flexible Imputation of Missing Data.pdf:/Users/Shehw001/Zotero/storage/2V4G5AEB/Buuren - Flexible Imputation of Missing Data.pdf:application/pdf},
}

@article{mengMultipleImputationInferencesUncongenial1994,
	title = {Multiple-{Imputation} {Inferences} with {Uncongenial} {Sources} of {Input}},
	volume = {9},
	issn = {0883-4237, 2168-8745},
	url = {https://projecteuclid.org/journals/statistical-science/volume-9/issue-4/Multiple-Imputation-Inferences-with-Uncongenial-Sources-of-Input/10.1214/ss/1177010269.full},
	doi = {10.1214/ss/1177010269},
	abstract = {Conducting sample surveys, imputing incomplete observations, and analyzing the resulting data are three indispensable phases of modern practice with public-use data files and with many other statistical applications. Each phase inherits different input, including the information preceding it and the intellectual assessments available, and aims to provide output that is one step closer to arriving at statistical inferences with scientific relevance. However, the role of the imputation phase has often been viewed as merely providing computational convenience for users of data. Although facilitating computation is very important, such a viewpoint ignores the imputer's assessments and information inaccessible to the users. This view underlies the recent controversy over the validity of multiple-imputation inference when a procedure for analyzing multiply imputed data sets cannot be derived from (is "uncongenial" to) the model adopted for multiple imputation. Given sensible imputations and complete-data analysis procedures, inferences from standard multiple-imputation combining rules are typically superior to, and thus different from, users' incomplete-data analyses. The latter may suffer from serious nonresponse biases because such analyses often must rely on convenient but unrealistic assumptions about the nonresponse mechanism. When it is desirable to conduct inferences under models for nonresponse other than the original imputation model, a possible alternative to recreating imputations is to incorporate appropriate importance weights into the standard combining rules. These points are reviewed and explored by simple examples and general theory, from both Bayesian and frequentist perspectives, particularly from the randomization perspective. Some convenient terms are suggested for facilitating communication among researchers from different perspectives when evaluating multiple-imputation inferences with uncongenial sources of input.},
	number = {4},
	urldate = {2024-04-17},
	journal = {Statistical Science},
	author = {Meng, Xiao-Li},
	month = nov,
	year = {1994},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {missing data, Congeniality, importance sampling, incomplete data, nonresponse, Normalizing constants, public-use data file, Randomization, self-efficiency},
	pages = {538--558},
	file = {Full Text PDF:/Users/Shehw001/Zotero/storage/NJ3AKY6J/Meng - 1994 - Multiple-Imputation Inferences with Uncongenial So.pdf:application/pdf},
}

@incollection{zotero-104,
}

@incollection{buurenMultipleImputation,
	title = {Multiple {Imputation}},
	language = {en},
	booktitle = {Flexible {Imputation} of {Missing} {Data}},
	author = {Buuren, Stef van},
	pages = {45--46},
}

@article{shahComparisonRandomForest2014a,
	title = {Comparison of random forest and parametric imputation models for imputing missing data using {MICE}: a {CALIBER} study},
	volume = {179},
	issn = {1476-6256},
	shorttitle = {Comparison of random forest and parametric imputation models for imputing missing data using {MICE}},
	doi = {10.1093/aje/kwt312},
	abstract = {Multivariate imputation by chained equations (MICE) is commonly used for imputing missing data in epidemiologic research. The "true" imputation model may contain nonlinearities which are not included in default imputation models. Random forest imputation is a machine learning technique which can accommodate nonlinearities and interactions and does not require a particular regression model to be specified. We compared parametric MICE with a random forest-based MICE algorithm in 2 simulation studies. The first study used 1,000 random samples of 2,000 persons drawn from the 10,128 stable angina patients in the CALIBER database (Cardiovascular Disease Research using Linked Bespoke Studies and Electronic Records; 2001-2010) with complete data on all covariates. Variables were artificially made "missing at random," and the bias and efficiency of parameter estimates obtained using different imputation methods were compared. Both MICE methods produced unbiased estimates of (log) hazard ratios, but random forest was more efficient and produced narrower confidence intervals. The second study used simulated data in which the partially observed variable depended on the fully observed variables in a nonlinear way. Parameter estimates were less biased using random forest MICE, and confidence interval coverage was better. This suggests that random forest imputation may be useful for imputing complex epidemiologic data sets in which some patients have missing data.},
	language = {eng},
	number = {6},
	journal = {American Journal of Epidemiology},
	author = {Shah, Anoop D. and Bartlett, Jonathan W. and Carpenter, James and Nicholas, Owen and Hemingway, Harry},
	month = mar,
	year = {2014},
	pmid = {24589914},
	pmcid = {PMC3939843},
	keywords = {imputation, missing data, Age Factors, angina, stable, Angina, Stable, Artificial Intelligence, Bias, Computer Simulation, Confidence Intervals, Epidemiologic Methods, Health Behavior, Health Status, Humans, missingness at random, Proportional Hazards Models, Random Allocation, regression trees, Sex Factors, simulation, survival},
	pages = {764--774},
	file = {Full Text:/Users/Shehw001/Zotero/storage/JQ25JUH2/Shah et al. - 2014 - Comparison of random forest and parametric imputat.pdf:application/pdf},
}

@incollection{buurenUnivariateMissingData,
	title = {Univariate missing data},
	language = {en},
	booktitle = {Flexible {Imputation} of {Missing} {Data}},
	author = {Buuren, Stef van},
	pages = {58},
}
